import io
import sys
import numpy as np
import pandas as pd
import streamlit as st
import matplotlib.pyplot as plt

from utils.data_preprocess import (
    normalize_columns,
    to_float_safe,
    extract_ata,
    cal_to_fh,
    compute_interval_efh,
    apply_mappings_ui
)
from utils.clustering import choose_k_elbow, kmeans_cluster_1d
from utils.compliance import compliance_check
from utils.nested import detect_nested_groups
from utils.export_utils import build_excel_report

st.set_page_config(page_title="AI Maintenance Task Optimizer", layout="wide")

# ---------------- Sidebar ‚Äì Parameters ----------------
st.sidebar.title("Thi·∫øt l·∫≠p")
st.sidebar.caption("Chu·∫©n ho√° EFH & r√†ng bu·ªôc k·ªπ thu·∫≠t")

# Quy ƒë·ªïi m·∫∑c ƒë·ªãnh (ƒë√£ th·ªëng nh·∫•t)
fc_to_fh_default = 4.83
mo_to_fh_default = 435.0

fc_to_fh = st.sidebar.number_input("Quy ƒë·ªïi 1 FC ‚Üí FH", value=fc_to_fh_default, step=0.01, min_value=0.1)
mo_to_fh = st.sidebar.number_input("Quy ƒë·ªïi 1 Month ‚Üí FH", value=mo_to_fh_default, step=1.0, min_value=10.0)

# Tolerance c·ªë ƒë·ªãnh theo y√™u c·∫ßu (20%)
tol = 0.20
st.sidebar.write(f"Tolerance (¬±) c·ªë ƒë·ªãnh: **{int(tol*100)}%**")

# Nested detection ¬±10% quanh b·ªôi 2
nested_eps = st.sidebar.slider("Nested: bi√™n ¬± quanh b·ªôi 2", min_value=0.05, max_value=0.2, value=0.10, step=0.01)
st.sidebar.caption("N·∫øu t·ª∑ l·ªá gi·ªØa 2 t√¢m li√™n ti·∫øp n·∫±m trong [2√ó(1-Œµ); 2√ó(1+Œµ)] ‚Üí nh√≥m nh·ªè nested v√†o nh√≥m l·ªõn.")

st.title("‚úàÔ∏è AI Maintenance Task Optimizer")
st.markdown("**M·ª•c ti√™u:** Gom nh√≥m theo chu k·ª≥ t·ª± nhi√™n (EFH), b·∫£o ƒë·∫£m **tu√¢n th·ªß ¬±20%**, v√† t√≠nh **nested 2√ó ¬±10%** ƒë·ªÉ gi·∫£m s·ªë l·∫ßn v√†o check.")

# ---------------- File Upload ----------------
uploaded = st.file_uploader("üìÇ T·∫£i file Task List (CSV/XLSX)", type=["csv", "xlsx"])
if not uploaded:
    st.info("T·∫£i l√™n file ƒë·ªÉ b·∫Øt ƒë·∫ßu. C√≥ th·ªÉ tham kh·∫£o `sample_data/a350_task_list_example.csv` trong repo.")
    st.stop()

# ---------------- Read Data ----------------
try:
    if uploaded.name.lower().endswith(".csv"):
        raw_df = pd.read_csv(uploaded)
    else:
        raw_df = pd.read_excel(uploaded)
except Exception as e:
    st.error(f"Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c file: {e}")
    st.stop()

st.subheader("1) D·ªØ li·ªáu g·ªëc (preview)")
st.dataframe(raw_df.head(20), use_container_width=True)

# ---------------- Column Mapping UI ----------------
st.subheader("2) √Ånh x·∫° c·ªôt b·∫Øt bu·ªôc")
df = raw_df.copy()
df.columns = [str(c).strip() for c in df.columns]
df_norm = normalize_columns(df)

mapping = apply_mappings_ui(df_norm.columns)
# Map c·ªôt theo l·ª±a ch·ªçn
df_work = df_norm.rename(columns={
    mapping["TASK"]: "TASK",
    mapping["TITLE"]: "TITLE",
    mapping["FH"]: "FH",
    mapping["CY"]: "CY",
    mapping["CAL"]: "CAL",
    mapping["CODE"]: "CODE",
    mapping["INT_THRES"]: "INT_THRES"
})

# Chu·∫©n ho√° gi√° tr·ªã s·ªë v√† ATA
for c in ["FH", "CY", "CAL"]:
    df_work[c] = df_work[c].apply(to_float_safe)
df_work["ATA"] = df_work["TASK"].apply(extract_ata)

# ---------------- EFH Conversion ----------------
st.subheader("3) Quy ƒë·ªïi sang EFH")
df_work["EFH_FH"] = df_work["FH"]
df_work["EFH_FC"] = df_work["CY"] * fc_to_fh
df_work["EFH_CAL"] = df_work.apply(lambda r: cal_to_fh(r["CAL"], r["CODE"], mo_to_fh), axis=1)
df_work["Interval_EFH"] = df_work.apply(
    lambda r: compute_interval_efh(r["EFH_FH"], r["EFH_FC"], r["EFH_CAL"]),
    axis=1
)
st.dataframe(df_work[["TASK","TITLE","ATA","FH","CY","CAL","CODE","EFH_FH","EFH_FC","EFH_CAL","Interval_EFH"]].head(20), use_container_width=True)

work = df_work[df_work["Interval_EFH"].notna() & (df_work["Interval_EFH"] > 0)].copy()
if work.empty:
    st.warning("Kh√¥ng c√≥ d√≤ng n√†o c√≥ `Interval_EFH` h·ª£p l·ªá.")
    st.stop()

# ---------------- KMeans Clustering ----------------
st.subheader("4) AI clustering theo EFH")
X = work[["Interval_EFH"]].values
best_model, k = choose_k_elbow(X, k_min=2, k_max=min(8, len(work)))
labels, centers = kmeans_cluster_1d(X, best_model)

work["Cluster"] = labels
# S·∫Øp x·∫øp t√¢m tƒÉng d·∫ßn v√† g√°n Group_ID
order = np.argsort(centers)
sorted_centers = [centers[i] for i in order]
label_map = {int(order[i]): i+1 for i in range(len(order))}
work["Group_ID"] = work["Cluster"].map(label_map)
group_center_map = {i+1: sorted_centers[i] for i in range(len(sorted_centers))}
work["Group_Center_EFH"] = work["Group_ID"].map(group_center_map)

# Bi·ªÉu ƒë·ªì ph√¢n b·ªë EFH v√† t√¢m c·ª•m
fig, ax = plt.subplots(figsize=(7,4))
ax.hist(work["Interval_EFH"], bins=30)
for c in sorted_centers:
    ax.axvline(c, linestyle="--")
ax.set_xlabel("Interval (EFH)")
ax.set_ylabel("Count")
ax.set_title("Ph√¢n b·ªë Interval_EFH & t√¢m c·ª•m")
st.pyplot(fig, use_container_width=True)

# ---------------- Compliance ¬±20% ----------------
st.subheader("5) Ki·ªÉm tra tu√¢n th·ªß h·∫°n (¬±20%) & ƒë√°nh d·∫•u Out-of-Phase")
work = compliance_check(work, tol=tol)  # th√™m Deviation_Ratio, Compliance_Status, Late_Risk

in_group = work[work["Compliance_Status"] == "In-Group"].copy()
ooph = work[work["Compliance_Status"] == "Out-of-Phase"].copy()

col_out = ["TASK","TITLE","ATA","FH","CY","CAL","CODE","Interval_EFH","Group_ID","Group_Center_EFH","Deviation_Ratio","Compliance_Status","Late_Risk"]
st.markdown("**In-Group (tu√¢n ¬±20%) ‚Äì preview**")
st.dataframe(in_group[col_out].head(100), use_container_width=True)
st.markdown("**Out-of-Phase (> ¬±20%) ‚Äì preview**")
st.dataframe(ooph[col_out].head(100), use_container_width=True)

# ---------------- Nested detection ----------------
st.subheader("6) Nested (b·ªôi 2 ¬±10%) v√† hi·ªáu qu·∫£ gi·∫£m s·ªë nh√≥m th·ª±c hi·ªán")
cent_df, effective_groups, effective_reduction = detect_nested_groups(sorted_centers, eps=nested_eps)

st.markdown("**T·ªïng quan Nested Summary**")
st.dataframe(cent_df, use_container_width=True)
st.write(f"**S·ªë nh√≥m th·ª±c c·∫ßn l√†m**: {len(effective_groups)} / {len(sorted_centers)}  ‚Üí  **Effective reduction:** {effective_reduction:.1%}")

# ---------------- Group Summary ----------------
st.subheader("7) Group Summary (ch·ªâ t√≠nh In-Group)")
summary = (in_group
           .groupby("Group_ID", as_index=False)
           .agg(
               Tasks=("TASK","count"),
               Mean_EFH=("Interval_EFH","mean"),
               Median_EFH=("Interval_EFH","median"),
               Min_EFH=("Interval_EFH","min"),
               Max_EFH=("Interval_EFH","max"),
               Center_EFH=("Group_Center_EFH","first")
           ))
summary["Suggested_Label"] = summary.apply(
    lambda r: f"Group-{int(r['Group_ID'])} (~{int(round(r['Center_EFH']))} EFH)",
    axis=1
)
st.dataframe(summary, use_container_width=True)

# ---------------- Download Excel ----------------
st.subheader("8) Xu·∫•t b√°o c√°o Excel")
buf = io.BytesIO()
assumptions = {
    "Chosen_k (elbow)": k,
    "FC_TO_FH": fc_to_fh,
    "MO_TO_FH": mo_to_fh,
    "Tolerance_¬±": tol,
    "Nested_Target_Ratio": 2.0,
    "Nested_EPS_¬±": nested_eps,
    "Effective_Groups": len(effective_groups),
    "Total_Groups": len(sorted_centers),
    "Effective_Reduction": effective_reduction
}
build_excel_report(
    buffer=buf,
    in_group_df=in_group[col_out],
    ooph_df=ooph[col_out],
    nested_df=cent_df,
    summary_df=summary,
    assumptions=assumptions
)
st.download_button(
    "‚¨áÔ∏è T·∫£i Excel k·∫øt qu·∫£",
    data=buf.getvalue(),
    file_name="AI_Compliance_Nested_Output.xlsx",
    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
)

st.success("Ho√†n t·∫•t. Anh c√≥ th·ªÉ d√πng file Excel n√†y ƒë·ªÉ tr√¨nh b√†y v√†/ho·∫∑c nh·∫≠p l·∫°i v√†o h·ªá th·ªëng l·∫≠p k·∫ø ho·∫°ch.")
